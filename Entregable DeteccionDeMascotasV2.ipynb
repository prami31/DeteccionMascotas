{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Entregable DetecciónDeMascotasV2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KHZzvFsWs7Z"
      },
      "source": [
        "# Deteccion de perros en timepo real"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn2Z__z6WSd0"
      },
      "source": [
        "Se carga la unidad drive a usar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHIfsnmm379Q",
        "outputId": "d590f41c-bb1a-4a60-d134-7c9952b05397"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ycLK6-NW7ri"
      },
      "source": [
        "# **Retinanet**\n",
        "Es un popular detector de una sola etapa, que es preciso y funciona rápido. RetinaNet utiliza una red piramidal de características para detectar objetos de manera eficiente a múltiples escalas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0md-A36qoa20",
        "outputId": "8d3eba25-04f1-4abe-8baf-578ff2653dc2"
      },
      "source": [
        "# Clonamos el repositorio de keras-retinanet\n",
        "!git clone https://github.com/DavidReveloLuna/keras-retinanet.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'keras-retinanet' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqxMxFP-Y2ok"
      },
      "source": [
        "#Desinstalacion e instalacion de librerias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maCe17MWYuHS"
      },
      "source": [
        "Desisntalamos las librerias por defecto para no generar conflicto de versiones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzJ7pr8Vo9Jg",
        "outputId": "803eb10e-2c46-421d-c093-66e21e130f14"
      },
      "source": [
        "!pip uninstall keras -y\n",
        "!pip uninstall keras-nightly -y\n",
        "!pip uninstall keras-Preprocessing -y\n",
        "!pip uninstall keras-vis -y\n",
        "!pip uninstall tensorflow -y\n",
        "!pip uninstall h5py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Keras 2.3.1\n",
            "Uninstalling Keras-2.3.1:\n",
            "  Successfully uninstalled Keras-2.3.1\n",
            "\u001b[33mWARNING: Skipping keras-nightly as it is not installed.\u001b[0m\n",
            "Found existing installation: Keras-Preprocessing 1.1.2\n",
            "Uninstalling Keras-Preprocessing-1.1.2:\n",
            "  Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "\u001b[33mWARNING: Skipping keras-vis as it is not installed.\u001b[0m\n",
            "Found existing installation: tensorflow 2.1.0\n",
            "Uninstalling tensorflow-2.1.0:\n",
            "  Successfully uninstalled tensorflow-2.1.0\n",
            "Found existing installation: h5py 2.10.0\n",
            "Uninstalling h5py-2.10.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py-2.10.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/h5py/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled h5py-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOOjBzJZY-SV"
      },
      "source": [
        "Instalamos librerias con las versiones que queremos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiLE26FXpNqJ",
        "outputId": "5ff20067-8e3a-42bf-f477-445ce8334b87"
      },
      "source": [
        "!pip install tensorflow==2.1.0\n",
        "!pip install keras==2.3.1\n",
        "!pip install h5py==2.10.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "  Using cached tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.39.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.19.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.37.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Collecting keras-preprocessing>=1.1.0\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (2.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.12.0)\n",
            "Collecting h5py\n",
            "  Using cached h5py-3.4.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.34.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.1.0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.7.4.3)\n",
            "Installing collected packages: h5py, keras-preprocessing, tensorflow\n",
            "Successfully installed h5py-3.4.0 keras-preprocessing-1.1.2 tensorflow-2.1.0\n",
            "Collecting keras==2.3.1\n",
            "  Using cached Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.1) (1.5.2)\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.3.1\n",
            "Collecting h5py==2.10.0\n",
            "  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.4.0\n",
            "    Uninstalling h5py-3.4.0:\n",
            "      Successfully uninstalled h5py-3.4.0\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIMNwEQpZPLv"
      },
      "source": [
        "Ingresamos al directorio de retinanet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-E1FUl2pf3W",
        "outputId": "d8003210-0526-4a65-f43b-9e70ee56bc7a"
      },
      "source": [
        "cd keras-retinanet/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/keras-retinanet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htIBDQY7ZTqx"
      },
      "source": [
        "Instalamos todas las librerias de python y usamos  el script setup.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnXNrL_qpivn",
        "outputId": "c20aa56b-efc1-48d6-93b5-c549ca1c8011"
      },
      "source": [
        "# Instalación y configuración de keras-retinet\n",
        "!pip install .\n",
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/keras-retinanet\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (2.3.1)\n",
            "Requirement already satisfied: keras-resnet==0.1.0 in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (0.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (1.4.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (0.29.24)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (4.1.2.30)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (3.38.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (3.13)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->keras-retinanet==0.5.1) (2.5.6)\n",
            "Building wheels for collected packages: keras-retinanet\n",
            "  Building wheel for keras-retinanet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-retinanet: filename=keras_retinanet-0.5.1-cp37-cp37m-linux_x86_64.whl size=170900 sha256=0683fd24af3f4122838d896462bd84848ba04ddc6facb990766643f5028ca869\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/29/34/9b33c07f08b1be9e77607c1fc6b08c679489aa7ddaed329652\n",
            "Successfully built keras-retinanet\n",
            "Installing collected packages: keras-retinanet\n",
            "  Attempting uninstall: keras-retinanet\n",
            "    Found existing installation: keras-retinanet 0.5.1\n",
            "    Uninstalling keras-retinanet-0.5.1:\n",
            "      Successfully uninstalled keras-retinanet-0.5.1\n",
            "Successfully installed keras-retinanet-0.5.1\n",
            "running build_ext\n",
            "skipping 'keras_retinanet/utils/compute_overlap.c' Cython extension (up-to-date)\n",
            "copying build/lib.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.cpython-37m-x86_64-linux-gnu.so -> keras_retinanet/utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evZRUKsgZqUl"
      },
      "source": [
        "Importamos librerias que se hara uso en el cuadernilllo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccHUuU1g-NsP"
      },
      "source": [
        "#\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "from sklearn.model_selection import train_test_split\n",
        "import urllib\n",
        "import os\n",
        "import csv\n",
        "import cv2\n",
        "import time\n",
        "from PIL import Image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0BVe0YyGgBV"
      },
      "source": [
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmUI4oGNpx3P"
      },
      "source": [
        "##Cargamos el modelo entrenado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G629f5Tbdg8"
      },
      "source": [
        "Este modelo es el resultado de 10 epocas de entrenamiento con 200 pasos, el cual represento una menor perdida en el entrenamiento =0.69, luego procedemos a cargar el modelo con retinanet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtfNiBLNp37R",
        "outputId": "6d1fc7b4-5402-4c53-a68b-d7d7671567de"
      },
      "source": [
        "# Con el modelo ya entrenado vamos a realizar predicciones\n",
        "# Cargamos el modelo entrenado, y lo configuramos para que sea compatible con retinanet\n",
        "#model_path = os.path.join('snapshots', sorted(os.listdir('snapshots'), reverse=True)[0])\n",
        "model_path = \"/content/drive/MyDrive/snapshots/resnet50_csv_10.h5\"\n",
        "print(model_path)\n",
        "\n",
        "model = models.load_model(model_path, backbone_name='resnet50')\n",
        "model = models.convert_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/snapshots/resnet50_csv_10.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-22.627417, -11.313708,  22.627417,  11.313708],\n",
            "       [-28.50876 , -14.25438 ,  28.50876 ,  14.25438 ],\n",
            "       [-35.918785, -17.959393,  35.918785,  17.959393],\n",
            "       [-16.      , -16.      ,  16.      ,  16.      ],\n",
            "       [-20.158737, -20.158737,  20.158737,  20.158737],\n",
            "       [-25.398417, -25.398417,  25.398417,  25.398417],\n",
            "       [-11.313708, -22.627417,  11.313708,  22.627417],\n",
            "       [-14.25438 , -28.50876 ,  14.25438 ,  28.50876 ],\n",
            "       [-17.959393, -35.918785,  17.959393,  35.918785]], dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-45.254833, -22.627417,  45.254833,  22.627417],\n",
            "       [-57.01752 , -28.50876 ,  57.01752 ,  28.50876 ],\n",
            "       [-71.83757 , -35.918785,  71.83757 ,  35.918785],\n",
            "       [-32.      , -32.      ,  32.      ,  32.      ],\n",
            "       [-40.317474, -40.317474,  40.317474,  40.317474],\n",
            "       [-50.796833, -50.796833,  50.796833,  50.796833],\n",
            "       [-22.627417, -45.254833,  22.627417,  45.254833],\n",
            "       [-28.50876 , -57.01752 ,  28.50876 ,  57.01752 ],\n",
            "       [-35.918785, -71.83757 ,  35.918785,  71.83757 ]], dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[ -90.50967 ,  -45.254833,   90.50967 ,   45.254833],\n",
            "       [-114.03504 ,  -57.01752 ,  114.03504 ,   57.01752 ],\n",
            "       [-143.67514 ,  -71.83757 ,  143.67514 ,   71.83757 ],\n",
            "       [ -64.      ,  -64.      ,   64.      ,   64.      ],\n",
            "       [ -80.63495 ,  -80.63495 ,   80.63495 ,   80.63495 ],\n",
            "       [-101.593666, -101.593666,  101.593666,  101.593666],\n",
            "       [ -45.254833,  -90.50967 ,   45.254833,   90.50967 ],\n",
            "       [ -57.01752 , -114.03504 ,   57.01752 ,  114.03504 ],\n",
            "       [ -71.83757 , -143.67514 ,   71.83757 ,  143.67514 ]],\n",
            "      dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-181.01933,  -90.50967,  181.01933,   90.50967],\n",
            "       [-228.07008, -114.03504,  228.07008,  114.03504],\n",
            "       [-287.35028, -143.67514,  287.35028,  143.67514],\n",
            "       [-128.     , -128.     ,  128.     ,  128.     ],\n",
            "       [-161.2699 , -161.2699 ,  161.2699 ,  161.2699 ],\n",
            "       [-203.18733, -203.18733,  203.18733,  203.18733],\n",
            "       [ -90.50967, -181.01933,   90.50967,  181.01933],\n",
            "       [-114.03504, -228.07008,  114.03504,  228.07008],\n",
            "       [-143.67514, -287.35028,  143.67514,  287.35028]], dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-362.03867, -181.01933,  362.03867,  181.01933],\n",
            "       [-456.14017, -228.07008,  456.14017,  228.07008],\n",
            "       [-574.70056, -287.35028,  574.70056,  287.35028],\n",
            "       [-256.     , -256.     ,  256.     ,  256.     ],\n",
            "       [-322.5398 , -322.5398 ,  322.5398 ,  322.5398 ],\n",
            "       [-406.37466, -406.37466,  406.37466,  406.37466],\n",
            "       [-181.01933, -362.03867,  181.01933,  362.03867],\n",
            "       [-228.07008, -456.14017,  228.07008,  456.14017],\n",
            "       [-287.35028, -574.70056,  287.35028,  574.70056]], dtype=float32)> anchors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpRQwSY1cMwN"
      },
      "source": [
        "Aqui cargamos el archivo que contiene las etiquetas de las clases que en nuestro caso es:\n",
        "```\n",
        "classes.csv :\n",
        "\n",
        "dog 0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOCVhN2gqQAZ"
      },
      "source": [
        "# Cargamos el archivo que contiene las etiquetas de las clases /content/drive/MyDrive/Proyecto Detección de Mascotas/classes.csv\n",
        "#labels_to_names = pd.read_csv('classes.csv', header=None).T.loc[0].to_dict()\n",
        "labels_to_names = pd.read_csv('/content/drive/MyDrive/classes.csv', header=None).T.loc[0].to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbxUnkRsc1Su"
      },
      "source": [
        "Obtenemos la predicción del modelo: boxes, scores, labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpXwUVUeqf4l"
      },
      "source": [
        "import skimage.io as io\n",
        "def predict(image):\n",
        "  image = preprocess_image(image.copy())\n",
        "  image, scale = resize_image(image)\n",
        "  boxes, scores, labels = model.predict_on_batch(\n",
        "    np.expand_dims(image, axis=0)\n",
        "  )\n",
        "  boxes /= scale\n",
        "  return boxes, scores, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fuES4todEUx"
      },
      "source": [
        "#Aqui cargamos el codigo para que podamos usar la webcam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBLO9Odpqt4T"
      },
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRijgYzTfZ4L"
      },
      "source": [
        "Cargamos mas librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQT0LSyyqydE"
      },
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "%matplotlib inline\n",
        "#Librería para generar la alarma\n",
        "from google.colab import output as son"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rmYQ9gKfmYy"
      },
      "source": [
        "Metodos para pasar el video leido con javascript a imagen en formato opencv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCTQOXWOq3KS"
      },
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JD2GUCEgJEN"
      },
      "source": [
        "#Porcentaje de similitud\n",
        "Funciones para comparar la similitud de las imagenes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFFNkJjfrBiQ"
      },
      "source": [
        "from skimage.metrics import structural_similarity\n",
        "\n",
        "#Módulo para comparar dos imágenes\n",
        "def Orb_Sim(Img1,Img2):\n",
        "    Orb=cv2.ORB_create()\n",
        "    #Puntos y descriptores\n",
        "    Puntos1,Descrip1=Orb.detectAndCompute(Img1,None)\n",
        "    Puntos2,Descrip2=Orb.detectAndCompute(Img2,None)\n",
        "    #Definimos el matcher\n",
        "    BF=cv2.BFMatcher(cv2.NORM_HAMMING,crossCheck=True)\n",
        "    #Realizamos el match\n",
        "    Matches=BF.match(Descrip1,Descrip2)\n",
        "    #Buscamos las regiones similares\n",
        "    RegionesSimilares=[I for I in Matches if I.distance<70]\n",
        "    if(len(Matches)==0):\n",
        "        return(0)\n",
        "    return(len(RegionesSimilares)/len(Matches))\n",
        "#Módulo para igualar las dimensiones de las imágenes\n",
        "def Dimensiones(Img1,Img2):\n",
        "    Sim,Dif=structural_similarity(Img1,Img2,full=True)\n",
        "    return Sim\n",
        "    #Fila inicial:final hasta columna inicial:final\n",
        "def Recortar(Fi,Ff,Ci,Cf,Img):\n",
        "    #Todos deben ser enteros\n",
        "    ImgRecorte=Img[Fi:Ff,Ci:Cf]\n",
        "    return(ImgRecorte)\n",
        "def Comparar(Img1,Img2):\n",
        "    Similitud=Orb_Sim(Img1,Img2)\n",
        "    Porcentaje=round((Similitud*100),2)\n",
        "    print(Porcentaje)\n",
        "    if(Porcentaje>90):\n",
        "        return(True)\n",
        "    else:\n",
        "        return(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-rwjkSVggfl"
      },
      "source": [
        "#Mostramos el video en timepo real y hacemos la comparacion \n",
        "La comparacion se hace entre la entrada del foto del can perdido y el actual fotograma que muestra el video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "3guDrQpCrPB4",
        "outputId": "50d16502-a8e8-4701-e906-9dcc3ad66fbf"
      },
      "source": [
        "#LEER la imagen del perro a buscar\n",
        "ImgPerroPerdido=cv2.imread(\"/content/negroPerdido.PNG\",0)\n",
        "#ImgPerroPerdido=cv2.imread(\"/content/pipoca2.jpg\",0)\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "    # convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "    # --------------------------------------------------------------------\n",
        "    boxes, scores, labels = predict(frame)\n",
        "    draw = frame.copy()\n",
        "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "        if score > 0.8:\n",
        "            print(box)            \n",
        "            b = box.astype(int)\n",
        "            color = label_color(label)\n",
        "            draw_box(draw, b, color=color)\n",
        "            caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "            draw_caption(draw, b, caption)       \n",
        "            bbox_array = cv2.rectangle(bbox_array,(int(b[0]),int(b[1])),(int(b[0]+b[2]),int(b[1]+b[3])),(255,0,0),2)            \n",
        "            ImgPerroEnVideo=Recortar(int(b[0]),int(b[3]),int(b[1]),int(b[2]),frame)     \n",
        "            if(Comparar(ImgPerroEnVideo,ImgPerroPerdido)):\n",
        "              son.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n",
        "              print(\"Te encontré\")\n",
        "              break\n",
        "            else:              \n",
        "              print(\"No eres tú\")\n",
        "    # --------------------------------------------------------------------\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes\n",
        "        \n",
        "camera.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-259075456f5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mjs_reply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_html\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjs_reply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-a05efe86d862>\u001b[0m in \u001b[0;36mvideo_frame\u001b[0;34m(label, bbox)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvideo_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stream_frame(\"{}\", \"{}\")'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: Cell has no view"
          ]
        }
      ]
    }
  ]
}